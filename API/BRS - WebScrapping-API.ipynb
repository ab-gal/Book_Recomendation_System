{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f68977b-dab6-4023-8c75-d87d121d2a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìö Basic libraries\n",
    "import pandas as pd\n",
    "\n",
    "#‚ùóNew Libraries !\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "# ‚öôÔ∏è Settings\n",
    "pd.set_option('display.max_columns', None) # display all columns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # ignore warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93601e8d-fa78-41ef-9ef3-f93c18063388",
   "metadata": {},
   "outputs": [],
   "source": [
    "link = \"https://openlibrary.org/search.json?q=subject_key%3A%22awards%22&page=26&limit=20\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ea12f3f-72d2-49e7-9690-9ef2e98cccab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.get(link)\n",
    "response.status_code # 200 status code means OK!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b0e1d94-6d19-4edf-8f99-c3fa959db7dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "# print(soup.prettify())\n",
    "# soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "393aa570-0f5f-4d36-90bc-5a24ca47c2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # \"key\":\"/works/OL18104072W\"\n",
    "# keys = soup.find_all(\"key\")\n",
    "# keys = keys.get_text()\n",
    "# keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "236a922c-2862-4958-9783-cd2f2b5fc403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# title: []\n",
    "# author: []\n",
    "# published_year : []\n",
    "# subject: []\n",
    "# language: []\n",
    "# cover_image: []\n",
    "\n",
    "# for page in range [26:50]:\n",
    "#     keys = []\n",
    "#     link_main = \"https://openlibrary.org/search.json?q=subject_key%3A%22awards%22&page=\" + page + '&limit=20'\n",
    "#     response = requests.get(link_main)\n",
    "#     soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "#     get_keys = soup.find_all(\"key\")\n",
    "#     keys = get_keys.get_text()\n",
    "#     # \"key\":\"/works/OL18104072W\"\n",
    "\n",
    "#     for key in keys:\n",
    "#         link_book = 'https://openlibrary.org' + key\n",
    "#         title.append\n",
    "#         author.append\n",
    "#         etc etc\n",
    "#         cover_image\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728cbd23-3e85-422e-a4d7-e04dcfa9d737",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a9366e3-e3b3-4c87-b030-c1dcfdc697fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "\n",
    "# # Store all book dictionaries here\n",
    "# books_data = []\n",
    "\n",
    "# headers = {\n",
    "#     'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "# }\n",
    "\n",
    "# # Loop Pages 26 to 50\n",
    "# for page in range(26, 28):\n",
    "#     print(f\"--- Processing Search Page {page} ---\")\n",
    "    \n",
    "#     # 1. SEARCH: Get the list of keys for this page\n",
    "#     search_url = f\"https://openlibrary.org/search.json?q=subject_key%3A%22awards%22&page={page}&limit=20\"\n",
    "    \n",
    "#     try:\n",
    "#         search_response = requests.get(search_url, headers=headers)\n",
    "#         if search_response.status_code != 200:\n",
    "#             print(f\"Skipping page {page} (Status {search_response.status_code})\")\n",
    "#             continue\n",
    "            \n",
    "#         search_results = search_response.json()\n",
    "        \n",
    "#         # Iterate through the 20 books found on this page\n",
    "#         for doc in search_results.get('docs', []):\n",
    "#             book_key = doc.get('key') # e.g., \"/works/OL18104072W\"\n",
    "            \n",
    "#             # We grab Author Name from search because the Book JSON usually only has Author IDs (e.g., OL123A), not names\n",
    "#             author_names = \", \".join(doc.get('author_name', []))\n",
    "            \n",
    "#             if not book_key:\n",
    "#                 continue\n",
    "\n",
    "#             # Construct URLs\n",
    "#             # JSON URL: Gets the detailed metadata (Publisher, Description, etc)\n",
    "#             book_json_url = f\"https://openlibrary.org{book_key}.json\"\n",
    "#             # HTML URL: Gets the visual page (for the Cover scraping)\n",
    "#             book_html_url = f\"https://openlibrary.org{book_key}\"\n",
    "\n",
    "#             print(f\"Fetching details for: {book_key}...\")\n",
    "\n",
    "#             # --- REQUEST 2: Get Specific Book JSON ---\n",
    "#             try:\n",
    "#                 json_resp = requests.get(book_json_url, headers=headers)\n",
    "#                 book_details = {}\n",
    "#                 if json_resp.status_code == 200:\n",
    "#                     book_details = json_resp.json()\n",
    "#             except:\n",
    "#                 book_details = {}\n",
    "\n",
    "#             # --- REQUEST 3: Get Specific Book HTML (For Cover) ---\n",
    "#             cover_url = None\n",
    "#             try:\n",
    "#                 html_resp = requests.get(book_html_url, headers=headers)\n",
    "#                 if html_resp.status_code == 200:\n",
    "#                     soup = BeautifulSoup(html_resp.content, 'html.parser')\n",
    "#                     # Find the cover tag as shown in your screenshot\n",
    "#                     cover_tag = soup.find(\"a\", class_=\"coverLook\")\n",
    "#                     if cover_tag and cover_tag.get('href'):\n",
    "#                         cover_url = \"https:\" + cover_tag.get('href')\n",
    "#             except:\n",
    "#                 cover_url = None\n",
    "\n",
    "#             # --- PARSE DETAILS FROM JSON ---\n",
    "#             # Title\n",
    "#             title = book_details.get('title', doc.get('title')) # Fallback to search title if JSON is empty\n",
    "            \n",
    "#             # Description (Sometimes it's a string, sometimes a dict: {'type':'text', 'value': '...'})\n",
    "#             desc_raw = book_details.get('description')\n",
    "#             description = None\n",
    "#             if isinstance(desc_raw, dict):\n",
    "#                 description = desc_raw.get('value')\n",
    "#             else:\n",
    "#                 description = desc_raw\n",
    "\n",
    "#             # Subjects (The detailed JSON list)\n",
    "#             subjects_list = book_details.get('subjects', [])\n",
    "#             subjects = \", \".join(subjects_list) if subjects_list else None\n",
    "\n",
    "#             # Publish Date (From detailed JSON)\n",
    "#             # Note: Works often store this in 'created' or 'first_publish_date', Editions use 'publish_date'\n",
    "#             pub_date = book_details.get('first_publish_date') or book_details.get('publish_date')\n",
    "            \n",
    "#             # Add to list\n",
    "#             books_data.append({\n",
    "#                 'Key': book_key,\n",
    "#                 'Title': title,\n",
    "#                 'Author': author_names,\n",
    "#                 'Published': pub_date,\n",
    "#                 'Subjects': subjects,\n",
    "#                 'Description': description,\n",
    "#                 'Cover Image': cover_url,\n",
    "#                 'JSON_URL': book_json_url\n",
    "#             })\n",
    "\n",
    "#             # IMPORTANT: Sleep to prevent IP Ban\n",
    "#             time.sleep(1.0)\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error on page {page}: {e}\")\n",
    "\n",
    "# # Save to DataFrame\n",
    "# df = pd.DataFrame(books_data)\n",
    "# print(\"Done! First 5 rows:\")\n",
    "# print(df.head())\n",
    "\n",
    "# # df.to_csv(\"detailed_books_awards.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47cadd02-6305-4c01-ae42-051e9ab85ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Processing Page 26: https://openlibrary.org/search.json?q=subject_key%3A%22awards%22&page=26&limit=20 ---\n",
      "--- Processing Page 27: https://openlibrary.org/search.json?q=subject_key%3A%22awards%22&page=27&limit=20 ---\n",
      "--- Processing Page 28: https://openlibrary.org/search.json?q=subject_key%3A%22awards%22&page=28&limit=20 ---\n",
      "--- Processing Page 29: https://openlibrary.org/search.json?q=subject_key%3A%22awards%22&page=29&limit=20 ---\n",
      "--- Processing Page 30: https://openlibrary.org/search.json?q=subject_key%3A%22awards%22&page=30&limit=20 ---\n",
      "--- Processing Page 31: https://openlibrary.org/search.json?q=subject_key%3A%22awards%22&page=31&limit=20 ---\n",
      "--- Processing Page 32: https://openlibrary.org/search.json?q=subject_key%3A%22awards%22&page=32&limit=20 ---\n",
      "--- Processing Page 33: https://openlibrary.org/search.json?q=subject_key%3A%22awards%22&page=33&limit=20 ---\n",
      "--- Processing Page 34: https://openlibrary.org/search.json?q=subject_key%3A%22awards%22&page=34&limit=20 ---\n",
      "--- Processing Page 35: https://openlibrary.org/search.json?q=subject_key%3A%22awards%22&page=35&limit=20 ---\n",
      "--- Processing Page 36: https://openlibrary.org/search.json?q=subject_key%3A%22awards%22&page=36&limit=20 ---\n",
      "--- Processing Page 37: https://openlibrary.org/search.json?q=subject_key%3A%22awards%22&page=37&limit=20 ---\n",
      "--- Processing Page 38: https://openlibrary.org/search.json?q=subject_key%3A%22awards%22&page=38&limit=20 ---\n",
      "--- Processing Page 39: https://openlibrary.org/search.json?q=subject_key%3A%22awards%22&page=39&limit=20 ---\n",
      "--- Processing Page 40: https://openlibrary.org/search.json?q=subject_key%3A%22awards%22&page=40&limit=20 ---\n",
      "--- Processing Page 41: https://openlibrary.org/search.json?q=subject_key%3A%22awards%22&page=41&limit=20 ---\n",
      "--- Processing Page 42: https://openlibrary.org/search.json?q=subject_key%3A%22awards%22&page=42&limit=20 ---\n",
      "--- Processing Page 43: https://openlibrary.org/search.json?q=subject_key%3A%22awards%22&page=43&limit=20 ---\n",
      "--- Processing Page 44: https://openlibrary.org/search.json?q=subject_key%3A%22awards%22&page=44&limit=20 ---\n",
      "--- Processing Page 45: https://openlibrary.org/search.json?q=subject_key%3A%22awards%22&page=45&limit=20 ---\n",
      "--- Processing Page 46: https://openlibrary.org/search.json?q=subject_key%3A%22awards%22&page=46&limit=20 ---\n",
      "--- Processing Page 47: https://openlibrary.org/search.json?q=subject_key%3A%22awards%22&page=47&limit=20 ---\n",
      "--- Processing Page 48: https://openlibrary.org/search.json?q=subject_key%3A%22awards%22&page=48&limit=20 ---\n",
      "--- Processing Page 49: https://openlibrary.org/search.json?q=subject_key%3A%22awards%22&page=49&limit=20 ---\n",
      "--- Processing Page 50: https://openlibrary.org/search.json?q=subject_key%3A%22awards%22&page=50&limit=20 ---\n",
      "--- Processing Page 51: https://openlibrary.org/search.json?q=subject_key%3A%22awards%22&page=51&limit=20 ---\n",
      "\n",
      "DataFrame Created Successfully:\n",
      "                                               title  \\\n",
      "0        Les Prix de Vertu, fond√©s par M. de Montyon   \n",
      "1  Teachers With Class... True Stories Of Great T...   \n",
      "2                    Rock and Roll Hall of Fame 1994   \n",
      "3                                 Stories of heroism   \n",
      "4                                    La colina vac√≠a   \n",
      "\n",
      "                                   author published_year  \\\n",
      "0                           Fr√©d√©ric Lock           1876   \n",
      "1  Marsha Serling Goldberg, Sonia Feldman     March 2003   \n",
      "2   Rock and Roll Hall of Fame Foundation           1994   \n",
      "3                          B. Chakravorty           None   \n",
      "4                              Ana Arn√°iz           None   \n",
      "\n",
      "                                             subject language  \\\n",
      "0  Montyon, Antoine-Jean-Baptiste-Robert Auget, b...      fre   \n",
      "1  Teaching, Teacher-student relationships, Educa...      eng   \n",
      "2  Rock and Roll Hall of Fame Foundation, History...      eng   \n",
      "3  Biography, Military decorations, Armed Forces,...     None   \n",
      "4  Awards, Architecture, History, Sculptors, Arch...     None   \n",
      "\n",
      "                                               cover  \n",
      "0  https://covers.openlibrary.org/b/id/6324499-L.jpg  \n",
      "1   https://covers.openlibrary.org/b/id/469736-L.jpg  \n",
      "2  https://covers.openlibrary.org/b/id/9964834-L.jpg  \n",
      "3                                               None  \n",
      "4                                               None  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "# 1. Initialize empty lists for the columns\n",
    "titles = []\n",
    "authors = []\n",
    "published_years = []\n",
    "subjects_list = []\n",
    "languages = []\n",
    "covers = []\n",
    "\n",
    "# Headers to act like a real browser\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "\n",
    "# 2. Loop through pages 26 to 50\n",
    "for page in range(26, 52):\n",
    "    \n",
    "    link_main = f\"https://openlibrary.org/search.json?q=subject_key%3A%22awards%22&page={page}&limit=20\"\n",
    "    print(f\"--- Processing Page {page}: {link_main} ---\")\n",
    "    \n",
    "    try:\n",
    "        # Get the Search API JSON\n",
    "        response = requests.get(link_main, headers=headers)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Skipping page {page} due to error.\")\n",
    "            continue\n",
    "            \n",
    "        data = response.json()\n",
    "        \n",
    "        # 3. Iterate through the keys in the search results\n",
    "        for doc in data.get('docs', []):\n",
    "            \n",
    "            # Prefer the 'cover_edition_key' (Book) if available, otherwise 'key' (Work)\n",
    "            # This ensures we get the JSON structure you posted (with publishers, etc.)\n",
    "            key_id = doc.get('cover_edition_key')\n",
    "            if key_id:\n",
    "                key = f\"/books/{key_id}\"\n",
    "            else:\n",
    "                # Fallback to Work key if no edition is found\n",
    "                key = doc.get('key')\n",
    "\n",
    "            if not key:\n",
    "                continue\n",
    "\n",
    "            # Construct URLs\n",
    "            link_book_json = f\"https://openlibrary.org{key}.json\"\n",
    "            link_book_html = f\"https://openlibrary.org{key}\"\n",
    "            \n",
    "            # --- PART A: GET DATA FROM BOOK JSON ---\n",
    "            try:\n",
    "                # Request the specific book JSON\n",
    "                book_resp = requests.get(link_book_json, headers=headers)\n",
    "                book_json = book_resp.json() if book_resp.status_code == 200 else {}\n",
    "                \n",
    "                # Title\n",
    "                t_val = book_json.get('title')\n",
    "                titles.append(t_val if t_val else None)\n",
    "                \n",
    "                # Author\n",
    "                # Note: The specific Book JSON usually only contains Author Keys (e.g. /authors/OL123A).\n",
    "                # To get the actual Name without making a 3rd Request, we take it from the Search Result (doc)\n",
    "                # If you strictly want it from the JSON, we would only get IDs. Here we use the name from search:\n",
    "                a_val = doc.get('author_name') # List\n",
    "                if a_val:\n",
    "                    authors.append(\", \".join(a_val))\n",
    "                else:\n",
    "                    authors.append(None)\n",
    "\n",
    "                # Published Year / Date\n",
    "                p_val = book_json.get('publish_date')\n",
    "                published_years.append(p_val if p_val else None)\n",
    "\n",
    "                # Subjects\n",
    "                # In your JSON example, this is a list of strings [\"Teaching\", \"Awards\"]\n",
    "                s_val = book_json.get('subjects')\n",
    "                if s_val and isinstance(s_val, list):\n",
    "                    subjects_list.append(\", \".join(s_val))\n",
    "                else:\n",
    "                    subjects_list.append(None)\n",
    "\n",
    "                # Language\n",
    "                # In your JSON example, this is [{\"key\": \"/languages/eng\"}]\n",
    "                l_val = book_json.get('languages')\n",
    "                if l_val and isinstance(l_val, list):\n",
    "                    # Extract just the code (e.g., 'eng') from '/languages/eng'\n",
    "                    langs = [item.get('key', '').split('/')[-1] for item in l_val if 'key' in item]\n",
    "                    languages.append(\", \".join(langs))\n",
    "                else:\n",
    "                    languages.append(None)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error parsing JSON for {key}: {e}\")\n",
    "                # Append None to keep lists aligned if fail\n",
    "                titles.append(None)\n",
    "                authors.append(None)\n",
    "                published_years.append(None)\n",
    "                subjects_list.append(None)\n",
    "                languages.append(None)\n",
    "\n",
    "            # --- PART B: GET COVER FROM HTML SCRAPING ---\n",
    "            try:\n",
    "                html_resp = requests.get(link_book_html, headers=headers)\n",
    "                cover_url = None\n",
    "                \n",
    "                if html_resp.status_code == 200:\n",
    "                    soup = BeautifulSoup(html_resp.content, 'html.parser')\n",
    "                    \n",
    "                    # Logic based on the website structure for the main cover\n",
    "                    # Usually found in an anchor tag with class 'coverLook' or 'cover'\n",
    "                    cover_tag = soup.find(\"a\", class_=\"coverLook\")\n",
    "                    \n",
    "                    if cover_tag and cover_tag.get('href'):\n",
    "                        cover_url = \"https:\" + cover_tag.get('href')\n",
    "                \n",
    "                covers.append(cover_url)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error scraping HTML for {key}: {e}\")\n",
    "                covers.append(None)\n",
    "\n",
    "            # Sleep to prevent IP ban (Essential!)\n",
    "            time.sleep(0.5)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Critical Error on Page {page}: {e}\")\n",
    "\n",
    "# 4. Create the Pandas DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'title': titles,\n",
    "    'author': authors,\n",
    "    'published_year': published_years,\n",
    "    'subject': subjects_list,\n",
    "    'language': languages,\n",
    "    'cover': covers\n",
    "})\n",
    "\n",
    "df_api = df.copy()\n",
    "# Display first few rows\n",
    "print(\"\\nDataFrame Created Successfully:\")\n",
    "print(df.head())\n",
    "\n",
    "# Save to CSV (Optional)\n",
    "# df.to_csv(\"books_scraped.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ef1478d-116f-4d51-b8e6-8df0a603c929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>published_year</th>\n",
       "      <th>subject</th>\n",
       "      <th>language</th>\n",
       "      <th>cover</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Les Prix de Vertu, fond√©s par M. de Montyon</td>\n",
       "      <td>Fr√©d√©ric Lock</td>\n",
       "      <td>1876</td>\n",
       "      <td>Montyon, Antoine-Jean-Baptiste-Robert Auget, b...</td>\n",
       "      <td>fre</td>\n",
       "      <td>https://covers.openlibrary.org/b/id/6324499-L.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Teachers With Class... True Stories Of Great T...</td>\n",
       "      <td>Marsha Serling Goldberg, Sonia Feldman</td>\n",
       "      <td>March 2003</td>\n",
       "      <td>Teaching, Teacher-student relationships, Educa...</td>\n",
       "      <td>eng</td>\n",
       "      <td>https://covers.openlibrary.org/b/id/469736-L.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rock and Roll Hall of Fame 1994</td>\n",
       "      <td>Rock and Roll Hall of Fame Foundation</td>\n",
       "      <td>1994</td>\n",
       "      <td>Rock and Roll Hall of Fame Foundation, History...</td>\n",
       "      <td>eng</td>\n",
       "      <td>https://covers.openlibrary.org/b/id/9964834-L.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stories of heroism</td>\n",
       "      <td>B. Chakravorty</td>\n",
       "      <td>None</td>\n",
       "      <td>Biography, Military decorations, Armed Forces,...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>La colina vac√≠a</td>\n",
       "      <td>Ana Arn√°iz</td>\n",
       "      <td>None</td>\n",
       "      <td>Awards, Architecture, History, Sculptors, Arch...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>Preise und Preistr√§ger der Stadt Wien</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Awards, Biography</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>Arte moderna portuguesa atrav√©s dos pr√©mios ar...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Awards, Portuguese Art</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>Souvenir, 1982, 7th State Film Award Festival</td>\n",
       "      <td>Dhirendranath Patnaik</td>\n",
       "      <td>None</td>\n",
       "      <td>Motion pictures, Motion picture industry, Awards</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>Svenskt glas '83</td>\n",
       "      <td>Helena Dahlb√§ck-Lutteman</td>\n",
       "      <td>None</td>\n",
       "      <td>Glassware, Awards, Exhibitions, History</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>Premio del Golfo</td>\n",
       "      <td>Marzia Ratti</td>\n",
       "      <td>None</td>\n",
       "      <td>Centro di arte moderna e contemporanea della S...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>520 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0          Les Prix de Vertu, fond√©s par M. de Montyon   \n",
       "1    Teachers With Class... True Stories Of Great T...   \n",
       "2                      Rock and Roll Hall of Fame 1994   \n",
       "3                                   Stories of heroism   \n",
       "4                                      La colina vac√≠a   \n",
       "..                                                 ...   \n",
       "515              Preise und Preistr√§ger der Stadt Wien   \n",
       "516  Arte moderna portuguesa atrav√©s dos pr√©mios ar...   \n",
       "517      Souvenir, 1982, 7th State Film Award Festival   \n",
       "518                                   Svenskt glas '83   \n",
       "519                                   Premio del Golfo   \n",
       "\n",
       "                                     author published_year  \\\n",
       "0                             Fr√©d√©ric Lock           1876   \n",
       "1    Marsha Serling Goldberg, Sonia Feldman     March 2003   \n",
       "2     Rock and Roll Hall of Fame Foundation           1994   \n",
       "3                            B. Chakravorty           None   \n",
       "4                                Ana Arn√°iz           None   \n",
       "..                                      ...            ...   \n",
       "515                                    None           None   \n",
       "516                                    None           None   \n",
       "517                   Dhirendranath Patnaik           None   \n",
       "518                Helena Dahlb√§ck-Lutteman           None   \n",
       "519                            Marzia Ratti           None   \n",
       "\n",
       "                                               subject language  \\\n",
       "0    Montyon, Antoine-Jean-Baptiste-Robert Auget, b...      fre   \n",
       "1    Teaching, Teacher-student relationships, Educa...      eng   \n",
       "2    Rock and Roll Hall of Fame Foundation, History...      eng   \n",
       "3    Biography, Military decorations, Armed Forces,...     None   \n",
       "4    Awards, Architecture, History, Sculptors, Arch...     None   \n",
       "..                                                 ...      ...   \n",
       "515                                  Awards, Biography     None   \n",
       "516                             Awards, Portuguese Art     None   \n",
       "517   Motion pictures, Motion picture industry, Awards     None   \n",
       "518            Glassware, Awards, Exhibitions, History     None   \n",
       "519  Centro di arte moderna e contemporanea della S...     None   \n",
       "\n",
       "                                                 cover  \n",
       "0    https://covers.openlibrary.org/b/id/6324499-L.jpg  \n",
       "1     https://covers.openlibrary.org/b/id/469736-L.jpg  \n",
       "2    https://covers.openlibrary.org/b/id/9964834-L.jpg  \n",
       "3                                                 None  \n",
       "4                                                 None  \n",
       "..                                                 ...  \n",
       "515                                               None  \n",
       "516                                               None  \n",
       "517                                               None  \n",
       "518                                               None  \n",
       "519                                               None  \n",
       "\n",
       "[520 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "899f4201-7bab-4f34-941d-1a947d1e7a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV (Optional)\n",
    "# df_api.to_csv(\"books_api_scraped.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39295873-d62e-4e20-b4ed-2347eab3cc55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title             515\n",
       "author            440\n",
       "published_year    144\n",
       "subject           459\n",
       "language           13\n",
       "cover             198\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_api.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "defe5147-79d4-47cc-98d3-f3349236e3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Processing Page 26 | Collected so far: 0/500 ---\n",
      " -> Added: Les Prix de Vertu, fond√©s par ...\n",
      " -> Added: Teachers With Class... True St...\n",
      " -> Added: Rock and Roll Hall of Fame 199...\n",
      " -> Added: The third annual Rock & Roll H...\n",
      " -> Added: Rock and Roll Hall of Fame 199...\n",
      " -> Added: The Rock and Roll Hall of Fame...\n",
      " -> Added: Print's Best Logos & Symbols 4...\n",
      " -> Added: World Press Photo 1999...\n",
      "--- Processing Page 27 | Collected so far: 8/500 ---\n",
      " -> Added: Nobel Lectures...\n",
      " -> Added: Pulitzer's Gold...\n",
      " -> Added: Zhurnalistika kak postupok...\n",
      "--- Processing Page 28 | Collected so far: 11/500 ---\n",
      " -> Added: The road to Stockholm...\n",
      " -> Added: The Nobel Peace Prize and the ...\n",
      " -> Added: A pictorial history of the Can...\n",
      " -> Added: A Century of Nobel Peace Prize...\n",
      " -> Added: The Pulitzer Prize Archive - S...\n",
      " -> Added: High Society...\n",
      " -> Added: Literature is freedom...\n",
      " -> Added: The Booker book...\n",
      "--- Processing Page 29 | Collected so far: 19/500 ---\n",
      " -> Added: The Guinness Book of Winners...\n",
      " -> Added: Das Haus der Gegenwart...\n",
      " -> Added: Pride of Place How England Inv...\n",
      " -> Added: Design juries on trial...\n",
      "--- Processing Page 30 | Collected so far: 23/500 ---\n",
      " -> Added: Prix offerts par la Soci√©t√© d'...\n",
      " -> Added: Who won what when...\n",
      " -> Added: Winners...\n",
      " -> Added: Premiums offered by the Quebec...\n",
      "--- Processing Page 31 | Collected so far: 27/500 ---\n",
      " -> Added: Deja Blue...\n",
      " -> Added: The National Service Trust Act...\n",
      " -> Added: Epica Book Sixteen: Europe's B...\n",
      " -> Added: The Malcolm Baldrige National ...\n",
      " -> Added: The Nobel Peace Prize Lecture...\n",
      "--- Processing Page 32 | Collected so far: 32/500 ---\n",
      " -> Added: Sustainable design...\n",
      " -> Added: If--then...\n",
      "--- Processing Page 33 | Collected so far: 34/500 ---\n",
      " -> Added: XII Premio Obras Cemex...\n",
      " -> Added: Zhonghua Minguo bao yang ling ...\n",
      " -> Added: Tatort Stadt II...\n",
      " -> Added: Commitment to Place...\n",
      "--- Processing Page 34 | Collected so far: 38/500 ---\n",
      " -> Added: Best Newspaper Writing, 2007-2...\n",
      " -> Added: The One Show, Vol. 26...\n",
      " -> Added: Instructions aux juges dans le...\n",
      " -> Added: Prizewinning literature...\n",
      " -> Added: Trial by jury....\n",
      " -> Added: Sporting glory...\n",
      " -> Added: Namen in sprachlichen Kontaktg...\n",
      " -> Added: Peace Women...\n",
      "--- Processing Page 35 | Collected so far: 46/500 ---\n",
      " -> Added: Scholarships, Grants & Prizes ...\n",
      " -> Added: The words of peace...\n",
      " -> Added: 58. Mostra internazionale d'ar...\n",
      " -> Added: Naturforscher und Gestalter de...\n",
      "--- Processing Page 36 | Collected so far: 50/500 ---\n",
      " -> Added: Politics of Excellence...\n",
      " -> Added: Ethnic book awards...\n",
      " -> Added: Awards, Honors & Prizes: Unite...\n",
      " -> Added: The most glittering prize...\n",
      " -> Added: In the realms of gold...\n",
      "--- Processing Page 37 | Collected so far: 55/500 ---\n",
      "--- Processing Page 38 | Collected so far: 55/500 ---\n",
      " -> Added: The emblems of the Altdorf Aca...\n",
      " -> Added: The Pulitzer Prizes, 1987 (Pul...\n",
      " -> Added: World Press Photo 2008 (World ...\n",
      " -> Added: Bp Portrait Award 2003...\n",
      " -> Added: Architecture for Islamic Socie...\n",
      " -> Added: Congressional recognition for ...\n",
      " -> Added: 1995 Best Newspaper Writing: W...\n",
      " -> Added: 3-Dimensional Illustrators Awa...\n",
      " -> Added: Great Men and Women of Asia ...\n",
      " -> Added: 3-Dimensional Illustration Awa...\n",
      " -> Added: Clio Awards...\n",
      "--- Processing Page 39 | Collected so far: 66/500 ---\n",
      " -> Added: Best Newspaper Writing 2003 (B...\n",
      " -> Added: Awards and Rewards for Grades ...\n",
      " -> Added: Awards and Rewards for K-3...\n",
      " -> Added: Designers' Handbook of Booklet...\n",
      " -> Added: On Becoming Exceptional...\n",
      " -> Added: For the Honor of the School...\n",
      " -> Added: La paix pour destin...\n",
      " -> Added: Winning With Promotion Power...\n",
      "--- Processing Page 40 | Collected so far: 74/500 ---\n",
      " -> Added: A Century Of Heroes...\n",
      " -> Added: Best Songs of the Movies...\n",
      " -> Added: European Union Prize for Conte...\n",
      " -> Added: Leading your Healthcare Organi...\n",
      " -> Added: Childrens Books Awards and Pri...\n",
      " -> Added: Wood Design Awards 2002...\n",
      " -> Added: Teacher of the year...\n",
      " -> Added: Awards, Honors & Prizes: Unite...\n",
      " -> Added: The Pura Belpre Awards...\n",
      " -> Added: Dynamite Women...\n",
      " -> Added: Architecture 05: The Guide to ...\n",
      " -> Added: Architecture 06: The Guide to ...\n",
      " -> Added: Architecture 07: The Guide to ...\n",
      " -> Added: Magill's Cinema Annual, 1982 (...\n",
      " -> Added: The reward system in British a...\n",
      "--- Processing Page 41 | Collected so far: 89/500 ---\n",
      " -> Added: Primary Awards Galore (Teacher...\n",
      " -> Added: Spirit of Enterprise...\n",
      " -> Added: Frontiers of Economics...\n",
      " -> Added: Restructuring the City...\n",
      " -> Added: 60 Years of the Outland Trophy...\n",
      " -> Added: Mies Van Der Rohe Award 2007...\n",
      " -> Added: Insights to Performance Excell...\n",
      " -> Added: Insights to Performance Excell...\n",
      " -> Added: Insights to Excellence 1996...\n",
      " -> Added: Idn Decade Design Awards...\n",
      " -> Added: Dotmov Festival 2004...\n",
      " -> Added: The webmaster's guide to glory...\n",
      "--- Processing Page 42 | Collected so far: 101/500 ---\n",
      " -> Added: Architecture in Perspective 10...\n",
      " -> Added: Safety Incentives...\n",
      " -> Added: Footprints...\n",
      " -> Added: Point of Purchase Design Annua...\n",
      " -> Added: Turner Prize (Tate Gallery Lon...\n",
      " -> Added: Congressional Gold Medals, 177...\n",
      " -> Added: The Calumet Collection...\n",
      " -> Added: Art Directors Annual 80 (Art D...\n",
      " -> Added: Handbook of scientific and tec...\n",
      " -> Added: Being Famous (10 Things You Ne...\n",
      "--- Processing Page 43 | Collected so far: 111/500 ---\n",
      "--- Processing Page 44 | Collected so far: 111/500 ---\n",
      " -> Added: Zhongguo guang bo dian shi xin...\n",
      " -> Added: Naked Ambition...\n",
      "--- Processing Page 45 | Collected so far: 113/500 ---\n",
      " -> Added: Lasting impressions...\n",
      " -> Added: Peterson's scholarships, grant...\n",
      " -> Added: Measuring up to the Baldrige...\n",
      " -> Added: A world beater...\n",
      " -> Added: Prize medal dahlias [catalog...\n",
      " -> Added: Winners of the first President...\n",
      "--- Processing Page 46 | Collected so far: 119/500 ---\n",
      " -> Added: A grand champion...\n",
      " -> Added: Prize winning peonies and othe...\n",
      " -> Added: History of the Loring Prize pl...\n",
      " -> Added: La distribuzione dei premj sol...\n",
      " -> Added: National honor awards for faci...\n",
      " -> Added: NEA opera honors...\n",
      " -> Added: Presidential design awards 198...\n",
      " -> Added: Presidential design awards 199...\n",
      " -> Added: CyberArts 2006 (Ars Electronic...\n",
      " -> Added: D&AD' 15...\n",
      " -> Added: Cyberarts 2000...\n",
      " -> Added: 32nd Publication Design Annual...\n",
      " -> Added: Designs of the year 2012...\n",
      " -> Added: Dahlia aristocrats from the Au...\n",
      "--- Processing Page 47 | Collected so far: 133/500 ---\n",
      " -> Added: Design awards...\n",
      " -> Added: Design for transportation nati...\n",
      " -> Added: BLM reclamation and sustainabl...\n",
      " -> Added: Le pot de nouilles...\n",
      " -> Added: Dr. Robert Buermann informal, ...\n",
      " -> Added: Families 1000...\n",
      " -> Added: In recognition of the Presiden...\n",
      " -> Added: \"A\" award to Logan County, Ill...\n",
      " -> Added: Continuacion de las actas de l...\n",
      " -> Added: A.WAY...\n",
      " -> Added: A bill to amend the Head Start...\n",
      "--- Processing Page 48 | Collected so far: 144/500 ---\n",
      " -> Added: Seventh annual 100 unsung hero...\n",
      " -> Added: Honorary degrees conferred in ...\n",
      " -> Added: Demokratie ist keine Gl√ºcksver...\n",
      "--- Processing Page 49 | Collected so far: 147/500 ---\n",
      " -> Added: Architecture Canada 2010...\n",
      " -> Added: IF communication design award ...\n",
      "--- Processing Page 50 | Collected so far: 149/500 ---\n",
      " -> Added: Best highrises 2014/15...\n",
      "--- Processing Page 51 | Collected so far: 150/500 ---\n",
      "--- Processing Page 52 | Collected so far: 150/500 ---\n",
      " -> Added: Di er jie CAFAM wei lai zhan...\n",
      "--- Processing Page 53 | Collected so far: 151/500 ---\n",
      " -> Added: Schweigen Schreiben Reden Schw...\n",
      "--- Processing Page 54 | Collected so far: 152/500 ---\n",
      " -> Added: Premio Nacional de Ciencia y T...\n",
      "--- Processing Page 55 | Collected so far: 153/500 ---\n",
      " -> Added: Alay sa kalinaw...\n",
      " -> Added: Les AmeÃÅricains et la LeÃÅgion ...\n",
      "--- Processing Page 56 | Collected so far: 155/500 ---\n",
      "--- Processing Page 57 | Collected so far: 155/500 ---\n",
      "--- Processing Page 58 | Collected so far: 155/500 ---\n",
      "--- Processing Page 59 | Collected so far: 155/500 ---\n",
      "--- Processing Page 60 | Collected so far: 155/500 ---\n",
      " -> Added: 2008 Onur √ñd√ºl√º altƒ±n madalyas...\n",
      "--- Processing Page 61 | Collected so far: 156/500 ---\n",
      " -> Added: Barbara...\n",
      "--- Processing Page 62 | Collected so far: 157/500 ---\n",
      " -> Added: The Coretta Scott King Awards,...\n",
      "--- Processing Page 63 | Collected so far: 158/500 ---\n",
      "--- Processing Page 64 | Collected so far: 158/500 ---\n",
      "--- Processing Page 65 | Collected so far: 158/500 ---\n",
      "--- Processing Page 66 | Collected so far: 158/500 ---\n",
      " -> Added: Variety International Film Gui...\n",
      " -> Added: Grants and Awards Available to...\n",
      " -> Added: Winning low energy building de...\n",
      "--- Processing Page 67 | Collected so far: 161/500 ---\n",
      "--- Processing Page 68 | Collected so far: 161/500 ---\n",
      " -> Added: Prix offerts par la SocieÃÅteÃÅ ...\n",
      " -> Added: New Brunswick Society for the ...\n",
      " -> Added: Estudio de condecoraciones rec...\n",
      "--- Processing Page 69 | Collected so far: 164/500 ---\n",
      " -> Added: The AIA gold medal...\n",
      " -> Added: 54. Mostra internazionale d'ar...\n",
      "--- Processing Page 70 | Collected so far: 166/500 ---\n",
      " -> Added: Great Men and Women of Asia Vo...\n",
      " -> Added: Great Men and Women of Asia Vo...\n",
      " -> Added: Great Men and Women of Asia Vo...\n",
      " -> Added: Photography Awards 2004...\n",
      " -> Added: The award movies...\n",
      "--- Processing Page 71 | Collected so far: 171/500 ---\n",
      " -> Added: Onursal doktor olamamanƒ±n buÃày...\n",
      " -> Added: Renzo Piano...\n",
      " -> Added: National honours and their nob...\n",
      "--- Processing Page 72 | Collected so far: 174/500 ---\n",
      " -> Added: Exposition agricole et industr...\n",
      "--- Processing Page 73 | Collected so far: 175/500 ---\n",
      " -> Added: H.R. 3591--to honor Ronald and...\n",
      "--- Processing Page 74 | Collected so far: 176/500 ---\n",
      " -> Added: Booktalking...\n",
      " -> Added: Design for Aging Review, Vol. ...\n",
      " -> Added: Peterson's Scholarships, Grant...\n",
      " -> Added: Scholarships, Grants & Prizes ...\n",
      " -> Added: Scholarships, Grants & Prizes ...\n",
      " -> Added: Scholarships, Grants & Prizes ...\n",
      " -> Added: Scholarships, Grants & Prizes,...\n",
      " -> Added: Scholarships, Grants, and Priz...\n",
      "--- Processing Page 75 | Collected so far: 184/500 ---\n",
      "--- Processing Page 76 | Collected so far: 184/500 ---\n",
      "--- Processing Page 77 | Collected so far: 184/500 ---\n",
      "--- Processing Page 78 | Collected so far: 184/500 ---\n",
      "--- Processing Page 79 | Collected so far: 184/500 ---\n",
      "--- Processing Page 80 | Collected so far: 184/500 ---\n",
      " -> Added: Premio Maretti...\n",
      "--- Processing Page 81 | Collected so far: 185/500 ---\n",
      "--- Processing Page 82 | Collected so far: 185/500 ---\n",
      "--- Processing Page 83 | Collected so far: 185/500 ---\n",
      "--- Processing Page 84 | Collected so far: 185/500 ---\n",
      "--- Processing Page 85 | Collected so far: 185/500 ---\n",
      " -> Added: Stefan Moses...\n",
      "--- Processing Page 86 | Collected so far: 186/500 ---\n",
      "--- Processing Page 87 | Collected so far: 186/500 ---\n",
      " -> Added: Nachbarschaft...\n",
      "--- Processing Page 88 | Collected so far: 187/500 ---\n",
      " -> Added: H√§user des Jahres...\n",
      "--- Processing Page 89 | Collected so far: 188/500 ---\n",
      "--- Processing Page 90 | Collected so far: 188/500 ---\n",
      " -> Added: The Hugo Boss Prize 2004...\n",
      "--- Processing Page 91 | Collected so far: 189/500 ---\n",
      "--- Processing Page 92 | Collected so far: 189/500 ---\n",
      " -> Added: Der deutsche Jugendliteraturpr...\n",
      "--- Processing Page 93 | Collected so far: 190/500 ---\n",
      "--- Processing Page 94 | Collected so far: 190/500 ---\n",
      " -> Added: Women of the century...\n",
      " -> Added: Arquia/pr√≥xima 2008...\n",
      " -> Added: The best book designs from the...\n",
      " -> Added: The national honours and award...\n",
      "--- Processing Page 95 | Collected so far: 194/500 ---\n",
      " -> Added: The Malcolm Baldrige Quality A...\n",
      "--- Processing Page 96 | Collected so far: 195/500 ---\n",
      " -> Added: The Nobel population 1901-1937...\n",
      "--- Processing Page 97 | Collected so far: 196/500 ---\n",
      "--- Processing Page 98 | Collected so far: 196/500 ---\n",
      " -> Added: Great Library Promotion Ideas ...\n",
      "--- Processing Page 99 | Collected so far: 197/500 ---\n",
      " -> Added: Por los caminos de Leloir...\n",
      " -> Added: Die Kulturpreise der Stiftung ...\n",
      "--- Processing Page 100 | Collected so far: 199/500 ---\n",
      " -> Added: Cyberarts 2001...\n",
      " -> Added: Ten young artists: Theodoron a...\n",
      " -> Added: Hugo Boss Prize, 2006....\n",
      " -> Added: Nine artists...\n",
      "--- Processing Page 101 | Collected so far: 203/500 ---\n",
      "--- Processing Page 102 | Collected so far: 203/500 ---\n",
      "--- Processing Page 103 | Collected so far: 203/500 ---\n",
      "--- Processing Page 104 | Collected so far: 203/500 ---\n",
      " -> Added: Employees suggestion program...\n",
      " -> Added: The Rise of Asian Design...\n",
      " -> Added: Improving management through t...\n",
      " -> Added: Suggestion awards program / He...\n",
      "--- Processing Page 105 | Collected so far: 207/500 ---\n",
      " -> Added: Sixty years with a camera...\n",
      "--- Processing Page 106 | Collected so far: 208/500 ---\n",
      " -> Added: Tony, Grammy, Emmy, Country...\n",
      " -> Added: Prime-time hits...\n",
      "--- Processing Page 107 | Collected so far: 210/500 ---\n",
      " -> Added: The BP Portrait Award 2002...\n",
      " -> Added: Liu Xiaobo dang an...\n",
      "--- Processing Page 108 | Collected so far: 212/500 ---\n",
      "--- Processing Page 109 | Collected so far: 212/500 ---\n",
      " -> Added: <30, X...\n",
      "--- Processing Page 110 | Collected so far: 213/500 ---\n",
      "--- Processing Page 111 | Collected so far: 213/500 ---\n",
      "--- Processing Page 112 | Collected so far: 213/500 ---\n",
      "--- Processing Page 113 | Collected so far: 213/500 ---\n",
      " -> Added: Per la solenne distribuzione d...\n",
      " -> Added: I.D.E.A....\n",
      " -> Added: Winning shopping center design...\n",
      "--- Processing Page 114 | Collected so far: 216/500 ---\n",
      " -> Added: Variety Presents...\n",
      " -> Added: Variety's directory of major U...\n",
      " -> Added: La obra actual de los ganadore...\n",
      " -> Added: The best American newspaper na...\n",
      " -> Added: Children's book prizes...\n",
      "--- Processing Page 115 | Collected so far: 221/500 ---\n",
      " -> Added: La Coupe Stanley d√©cod√©e...\n",
      " -> Added: The Jim Thorpe Award...\n",
      " -> Added: De best verzorgde boeken, 2007...\n",
      " -> Added: Gold Medal for Italian Archite...\n",
      " -> Added: Stolpersteine...\n",
      " -> Added: The Jerwood Drawing Prize...\n",
      " -> Added: Outstanding Broadway dramas an...\n",
      " -> Added: The world's biggest book of ph...\n",
      "--- Processing Page 116 | Collected so far: 229/500 ---\n",
      " -> Added: Homeless at age 13 to a colleg...\n",
      " -> Added: Hockey's Heroes 1994 (Year in ...\n",
      " -> Added: The national convention badges...\n",
      " -> Added: Baseball's best...\n",
      "--- Processing Page 117 | Collected so far: 233/500 ---\n",
      " -> Added: The Dobell prize for drawing...\n",
      " -> Added: Huan qiu huo jiang dian ying d...\n",
      "--- Processing Page 118 | Collected so far: 235/500 ---\n",
      "Error parsing JSON for /works/OL22767122W: HTTPSConnectionPool(host='openlibrary.org', port=443): Max retries exceeded with url: /works/OL22767122W.json (Caused by ConnectTimeoutError(<HTTPSConnection(host='openlibrary.org', port=443) at 0x13eeb139810>, 'Connection to openlibrary.org timed out. (connect timeout=None)'))\n",
      "--- Processing Page 119 | Collected so far: 235/500 ---\n",
      "--- Processing Page 120 | Collected so far: 235/500 ---\n",
      "Error parsing JSON for /works/OL38610044W: HTTPSConnectionPool(host='openlibrary.org', port=443): Max retries exceeded with url: /works/OL38610044W.json (Caused by ConnectTimeoutError(<HTTPSConnection(host='openlibrary.org', port=443) at 0x13eeb13b9d0>, 'Connection to openlibrary.org timed out. (connect timeout=None)'))\n",
      "Error parsing JSON for /works/OL38734178W: HTTPSConnectionPool(host='openlibrary.org', port=443): Max retries exceeded with url: /works/OL38734178W.json (Caused by ConnectTimeoutError(<HTTPSConnection(host='openlibrary.org', port=443) at 0x13eeb1391d0>, 'Connection to openlibrary.org timed out. (connect timeout=None)'))\n",
      "--- Processing Page 121 | Collected so far: 235/500 ---\n",
      "--- Processing Page 122 | Collected so far: 235/500 ---\n",
      " -> Added: Die Berliner Akademie der Wiss...\n",
      "--- Processing Page 123 | Collected so far: 236/500 ---\n",
      "--- Processing Page 124 | Collected so far: 236/500 ---\n",
      "--- Processing Page 125 | Collected so far: 236/500 ---\n",
      "--- Processing Page 126 | Collected so far: 236/500 ---\n",
      " -> Added: Characteristics of compassion...\n",
      "--- Processing Page 127 | Collected so far: 237/500 ---\n",
      "--- Processing Page 128 | Collected so far: 237/500 ---\n",
      " -> Added: BRAVERY AWARDS FOR AERIAL COMB...\n",
      "--- Processing Page 129 | Collected so far: 238/500 ---\n",
      "--- Processing Page 130 | Collected so far: 238/500 ---\n",
      "--- Processing Page 131 | Collected so far: 238/500 ---\n",
      "--- Processing Page 132 | Collected so far: 238/500 ---\n",
      "--- Processing Page 133 | Collected so far: 238/500 ---\n",
      "--- Processing Page 134 | Collected so far: 238/500 ---\n",
      "--- Processing Page 135 | Collected so far: 238/500 ---\n",
      "--- Processing Page 136 | Collected so far: 238/500 ---\n",
      " -> Added: I premi del cinema, 1927-1990...\n",
      " -> Added: Children's book awards interna...\n",
      " -> Added: Der Agon im Mythos...\n",
      "--- Processing Page 137 | Collected so far: 241/500 ---\n",
      " -> Added: Past to present...\n",
      " -> Added: Music from far and wide...\n",
      "--- Processing Page 138 | Collected so far: 243/500 ---\n",
      " -> Added: Variety major U.S. showbusines...\n",
      "--- Processing Page 139 | Collected so far: 244/500 ---\n",
      " -> Added: Saishin bunkash≈ç jiten, 1996-2...\n",
      " -> Added: Best newspaper writing 2006-20...\n",
      " -> Added: The Pocket guide to the Baldri...\n",
      " -> Added: Two projects by Foster and Par...\n",
      " -> Added: Last minute flash...\n",
      " -> Added: Champions for peace...\n",
      "--- Processing Page 140 | Collected so far: 250/500 ---\n",
      " -> Added: -40...\n",
      " -> Added: Glaskunst 81...\n",
      "--- Processing Page 141 | Collected so far: 252/500 ---\n",
      " -> Added: Clio Awards...\n",
      " -> Added: Handbuch der Kulturpreise 4 =...\n",
      " -> Added: Editorial excellence in busine...\n",
      " -> Added: Print's best typography...\n",
      " -> Added: Children's Book Award Handbook...\n",
      "--- Processing Page 142 | Collected so far: 257/500 ---\n",
      " -> Added: The National Book Awards for f...\n",
      " -> Added: Sonny's Birthday Prize...\n",
      " -> Added: [Bodger Seeds, Ltd. letters an...\n",
      " -> Added: Gladiolus price list...\n",
      "--- Processing Page 143 | Collected so far: 261/500 ---\n",
      " -> Added: Flintridge Foundation awards f...\n",
      " -> Added: Nihon no sh≈ç jiten...\n",
      " -> Added: Xue yuan xie ying...\n",
      "--- Processing Page 144 | Collected so far: 264/500 ---\n",
      " -> Added: The Pulitzer Prize photographs...\n",
      " -> Added: Die H√§lfte des Himmels...\n",
      " -> Added: From The Pain Come The Dream...\n",
      " -> Added: What every man wants...\n",
      " -> Added: Red Dot Communication Design Y...\n",
      "--- Processing Page 145 | Collected so far: 269/500 ---\n",
      " -> Added: Russkie nagrady...\n",
      " -> Added: CyberArts 2015...\n",
      " -> Added: Chronicle of the Pulitzer priz...\n",
      " -> Added: Chronicle of the Pulitzer Priz...\n",
      "--- Processing Page 146 | Collected so far: 273/500 ---\n",
      " -> Added: Premiums offered by the Societ...\n",
      " -> Added: La jeunesse est un art...\n",
      " -> Added: Newbery & Caldecott Awards...\n",
      " -> Added: Die SaÃàule am Rande des Kontin...\n",
      " -> Added: The school the Aztec Eagles bu...\n",
      " -> Added: Print's best corporate publica...\n",
      "--- Processing Page 147 | Collected so far: 279/500 ---\n",
      " -> Added: Kunst Kunst Kunst...\n",
      " -> Added: Facts and Forms...\n",
      " -> Added: Designs of Our Time...\n",
      "--- Processing Page 148 | Collected so far: 282/500 ---\n",
      " -> Added: Premio Nacional de Ciencias y ...\n",
      "--- Processing Page 149 | Collected so far: 283/500 ---\n",
      " -> Added: Entertainment Hall of Fame...\n",
      " -> Added: Jin pai bei hou...\n",
      " -> Added: Oscar Cullmann...\n",
      "--- Processing Page 150 | Collected so far: 286/500 ---\n",
      " -> Added: Tarnished Heisman...\n",
      "--- Processing Page 151 | Collected so far: 287/500 ---\n",
      "--- Processing Page 152 | Collected so far: 287/500 ---\n",
      " -> Added: H.R. 3591--to honor Ronald and...\n",
      "--- Processing Page 153 | Collected so far: 288/500 ---\n",
      "--- Processing Page 154 | Collected so far: 288/500 ---\n",
      "--- Processing Page 155 | Collected so far: 288/500 ---\n",
      " -> Added: The NASA space medals...\n",
      "--- Processing Page 156 | Collected so far: 289/500 ---\n",
      "--- Processing Page 157 | Collected so far: 289/500 ---\n",
      "--- Processing Page 158 | Collected so far: 289/500 ---\n",
      "--- Processing Page 159 | Collected so far: 289/500 ---\n",
      "--- Processing Page 160 | Collected so far: 289/500 ---\n",
      "--- Processing Page 161 | Collected so far: 289/500 ---\n",
      "--- Processing Page 162 | Collected so far: 289/500 ---\n",
      " -> Added: Forman's Guide to Third Reich ...\n",
      "--- Processing Page 163 | Collected so far: 290/500 ---\n",
      " -> Added: Basil Brush gets a medal...\n",
      "--- Processing Page 164 | Collected so far: 291/500 ---\n",
      " -> Added: Marks of achievement...\n",
      " -> Added: Mary and Jim Semans, North Car...\n",
      " -> Added: How to start and promote a saf...\n",
      " -> Added: Racing cups 1595 to 1850...\n",
      " -> Added: Best in Annual Reports (Best i...\n",
      "--- Processing Page 165 | Collected so far: 296/500 ---\n",
      " -> Added: Innovating America...\n",
      " -> Added: Pioneering Spirits...\n",
      " -> Added: Die Plakette der Medizinischen...\n",
      " -> Added: Denkmalpflege in Europa...\n",
      "--- Processing Page 166 | Collected so far: 300/500 ---\n",
      " -> Added: Energie effektiv nutzen...\n",
      " -> Added: Architecture 00...\n",
      " -> Added: Architecture 03: The Riba Awar...\n",
      "--- Processing Page 167 | Collected so far: 303/500 ---\n",
      " -> Added: Pulitzer's gold...\n",
      " -> Added: Randolph J. Caldecott and the ...\n",
      " -> Added: Honours and awards to women to...\n",
      " -> Added: Vision...\n",
      " -> Added: European Union Prize For Conte...\n",
      " -> Added: Param Vir Chakra...\n",
      "--- Processing Page 168 | Collected so far: 309/500 ---\n",
      " -> Added: The Avisson book of contests a...\n",
      "--- Processing Page 169 | Collected so far: 310/500 ---\n",
      " -> Added: Innovation Inducement Prizes a...\n",
      " -> Added: Economia--Una Ciencia, Muchas ...\n",
      " -> Added: World Changing Ideas...\n",
      " -> Added: Il Teatro d'onore...\n",
      " -> Added: Liste des prix offerts √† l'exp...\n",
      " -> Added: [Circulaire]...\n",
      "--- Processing Page 170 | Collected so far: 316/500 ---\n",
      " -> Added: Prize list...\n",
      " -> Added: Un prix litt√©raire √† Rouen au ...\n",
      " -> Added: Exposition scolaire de la prov...\n",
      "--- Processing Page 171 | Collected so far: 319/500 ---\n",
      " -> Added: Texas Aggie Medals of Honor...\n",
      " -> Added: Excellence in direct marketing...\n",
      " -> Added: Print's best logos & symbols 3...\n",
      "--- Processing Page 172 | Collected so far: 322/500 ---\n",
      " -> Added: The Thomas Jefferson Foundatio...\n",
      "--- Processing Page 173 | Collected so far: 323/500 ---\n",
      " -> Added: Portraits of Nobel laureates i...\n",
      " -> Added: The Words of peace...\n",
      " -> Added: The words of peace...\n",
      " -> Added: Peacemakers...\n",
      " -> Added: Educational Depository. Scient...\n",
      " -> Added: Ninth Annual Governor's Pollut...\n",
      " -> Added: The Hugo Boss prize 1998...\n",
      "--- Processing Page 174 | Collected so far: 330/500 ---\n",
      " -> Added: Otchet o ... prisuzhdenƒ´i nagr...\n",
      " -> Added: The Coretta Scott King Awards,...\n",
      " -> Added: Major award decisionmaking at ...\n",
      " -> Added: A single but huge distinction...\n",
      " -> Added: William Gaston as a public man...\n",
      " -> Added: Print's best booklets & brochu...\n",
      " -> Added: The Commonwealth Awards in the...\n",
      " -> Added: National Medal of Arts...\n",
      " -> Added: Massachusetts Black Legislativ...\n",
      " -> Added: Massachusetts drug fighters of...\n",
      "--- Processing Page 175 | Collected so far: 340/500 ---\n",
      " -> Added: Focus Energy...\n",
      " -> Added: Architecture and Polyphony...\n",
      " -> Added: Advertising works 15...\n",
      " -> Added: The Prix de Rome in architectu...\n",
      "--- Processing Page 176 | Collected so far: 344/500 ---\n",
      " -> Added: Developing digital architectur...\n",
      " -> Added: Legacies for the future...\n",
      "--- Processing Page 177 | Collected so far: 346/500 ---\n",
      " -> Added: Print's best logos & symbols 2...\n",
      " -> Added: Situating...\n",
      " -> Added: Rock and Roll Hall of Fame sev...\n",
      " -> Added: The Coretta Scott King awards,...\n",
      " -> Added: 1926 Ohio's blue book on dahli...\n",
      " -> Added: 1924 Ohio's blue book on dahli...\n",
      " -> Added: Noms des artistes...\n",
      " -> Added: Rapport fait par Dubois-Dubais...\n",
      " -> Added: Fifth presentation of the Char...\n",
      " -> Added: 1929 Gold medal roses...\n",
      " -> Added: Introducing some of the new pr...\n",
      " -> Added: 1925 Ohio's blue book on dahli...\n",
      "--- Processing Page 178 | Collected so far: 358/500 ---\n",
      " -> Added: Peterson's scholarships, grant...\n",
      " -> Added: Quebec Agricultural Society...\n",
      " -> Added: People almanac...\n",
      " -> Added: Fatou, Julia, Montel...\n",
      " -> Added: Charles McGee...\n",
      " -> Added: Filmschauen 1982 =...\n",
      "--- Processing Page 179 | Collected so far: 364/500 ---\n",
      " -> Added: Mildred Louise (Wentworth)...\n",
      " -> Added: The Kerlan Awards in children'...\n",
      " -> Added: Press photography awards, 1942...\n",
      "--- Processing Page 180 | Collected so far: 367/500 ---\n",
      " -> Added: 50 Jahre Auszeichnungen fuÃàr g...\n",
      " -> Added: The new black grape, Hubbard...\n",
      " -> Added: Rapport fait a   l'Assemble e ...\n",
      " -> Added: Stark golden delicious...\n",
      " -> Added: La distribuzione dei premj sol...\n",
      " -> Added: Opinion de Perre e (de Granvil...\n",
      " -> Added: Making history...\n",
      " -> Added: Leading the way...\n",
      "--- Processing Page 181 | Collected so far: 375/500 ---\n",
      " -> Added: Golden jubilee world tribute t...\n",
      " -> Added: Building for tomorrow...\n",
      "--- Processing Page 182 | Collected so far: 377/500 ---\n",
      " -> Added: Premi e incentivi alle traduzi...\n",
      "--- Processing Page 183 | Collected so far: 378/500 ---\n",
      " -> Added: A Missouri playwrights' anthol...\n",
      " -> Added: Architecture for a changing wo...\n",
      "--- Processing Page 184 | Collected so far: 380/500 ---\n",
      " -> Added: Nobel lectures in peace, 1996-...\n",
      "--- Processing Page 185 | Collected so far: 381/500 ---\n",
      " -> Added: The Kennedy Center American Co...\n",
      " -> Added: Timor Leste, Nobel da Paz...\n",
      " -> Added: Architecture beyond architectu...\n",
      "--- Processing Page 186 | Collected so far: 384/500 ---\n",
      " -> Added: Prize list of the County of Br...\n",
      " -> Added: 1899 Prize list...\n",
      " -> Added: 50 ans, Affiches suisses prime...\n",
      " -> Added: Editorial cartoon awards, 1922...\n",
      " -> Added: List of prize winning glads fo...\n",
      " -> Added: Awards and recognition program...\n",
      "--- Processing Page 187 | Collected so far: 390/500 ---\n",
      " -> Added: Twentieth annual exhibition at...\n",
      " -> Added: Il Teatro d'onore...\n",
      " -> Added: Seventh Annual Governor's Poll...\n",
      " -> Added: My love affair with Carolina...\n",
      " -> Added: Roots and branches...\n",
      " -> Added: Glimmers in the gloaming...\n",
      " -> Added: A resum√© of two historic adven...\n",
      " -> Added: The grandfathers...\n",
      " -> Added: Presidential design awards...\n",
      " -> Added: Sixth Annual Governor's Pollut...\n",
      " -> Added: Emblemata anniversaria Academi...\n",
      " -> Added: Eighth Annual Governor's Pollu...\n",
      "--- Processing Page 188 | Collected so far: 402/500 ---\n",
      " -> Added: The Coretta Scott King awards ...\n",
      " -> Added: The Pulitzer prizes...\n",
      " -> Added: Print's best logos & symbols 2...\n",
      " -> Added: ReSource...\n",
      "--- Processing Page 189 | Collected so far: 406/500 ---\n",
      " -> Added: Rapport fait par Heurtault-Lam...\n",
      " -> Added: Motion d'ordre faite par Bigon...\n",
      " -> Added: Rapport fait au nom du Comite ...\n",
      " -> Added: A New Brooklyn Museum...\n",
      " -> Added: System Landschaft...\n",
      " -> Added: The spirit of the city...\n",
      " -> Added: Loi relative a   la pe tition ...\n",
      " -> Added: Thirteenth presentation of the...\n",
      " -> Added: Eleventh presentation of the C...\n",
      " -> Added: Seventh presentation of the Ch...\n",
      " -> Added: Second presentation of the Cha...\n",
      " -> Added: Tenth presentation of the Char...\n",
      " -> Added: Sixth presentation of the Char...\n",
      " -> Added: Fourth presentation of the Cha...\n",
      "--- Processing Page 190 | Collected so far: 420/500 ---\n",
      " -> Added: Twelfth presentation of the Ch...\n",
      " -> Added: Third presentation of the Char...\n",
      " -> Added: Coleman's prize winning origin...\n",
      " -> Added: First Debate of the Philodemic...\n",
      " -> Added: 1928 Ohio's blue book on dahli...\n",
      " -> Added: Gold medal roses for 1929...\n",
      " -> Added: Retail catalogue, 1928...\n",
      " -> Added: Gold medal list of dahlias and...\n",
      " -> Added: Coleman's prize winning origin...\n",
      " -> Added: 1927 Ohio's blue book on dahli...\n",
      " -> Added: Dahlia aristocrats from the Au...\n",
      " -> Added: Prize winning gladiolus...\n",
      " -> Added: Lettre du roi a   M. l'amiral...\n",
      " -> Added: Re flexions sur les concours e...\n",
      " -> Added: Distribution des prix aux e le...\n",
      " -> Added: Extrait du proce  s-verbal de ...\n",
      " -> Added: Ecole-centrale du de partement...\n",
      "--- Processing Page 191 | Collected so far: 437/500 ---\n",
      " -> Added: Distribution des prix de l'e c...\n",
      " -> Added: ... Arr^ete...\n",
      " -> Added: Proce  s-verbal de la distribu...\n",
      " -> Added: Rapport et projet de de cret, ...\n",
      " -> Added: Special offers of the prize wi...\n",
      " -> Added: De cret de la Convention natio...\n",
      " -> Added: The winning plan...\n",
      " -> Added: Loi portant que le pre sident ...\n",
      " -> Added: Discours du pre sident de l'E ...\n",
      "--- Processing Page 192 | Collected so far: 446/500 ---\n",
      " -> Added: The gladiolus...\n",
      " -> Added: Grand prize strain gladioli [p...\n",
      " -> Added: Distribution des prix de l'e c...\n",
      " -> Added: Contemporary masters...\n",
      " -> Added: Print's best illustration & ph...\n",
      "--- Processing Page 193 | Collected so far: 451/500 ---\n",
      " -> Added: Neues Bauen in den Alpen...\n",
      " -> Added: Fresher facts...\n",
      "--- Processing Page 194 | Collected so far: 453/500 ---\n",
      " -> Added: Spirit of enterprise...\n",
      " -> Added: Supplementary list to Forbes &...\n",
      " -> Added: Concerning federally sponsored...\n",
      " -> Added: Illinois Environmental Protect...\n",
      " -> Added: Illinois Environmental Protect...\n",
      " -> Added: Governor's Home Town Award, 20...\n",
      " -> Added: 1917 Grand prix dahlias...\n",
      "--- Processing Page 195 | Collected so far: 460/500 ---\n",
      " -> Added: Die Zeitschrift MUT...\n",
      " -> Added: Explication exacte de tous les...\n",
      " -> Added: 1930 Gold medal rose, Presiden...\n",
      " -> Added: The best of the Rolex Awards f...\n",
      " -> Added: Discours du roi √† l'occasion d...\n",
      " -> Added: Seconde exposition publique de...\n",
      " -> Added: Peterson's scholarships, grant...\n",
      " -> Added: Recognizing excellence in the ...\n",
      " -> Added: The Turner Prize...\n",
      "--- Processing Page 196 | Collected so far: 469/500 ---\n",
      " -> Added: Hockey's heroes...\n",
      " -> Added: Personal narratives...\n",
      " -> Added: Situating...\n",
      " -> Added: Cyberarts 99...\n",
      " -> Added: The Nobel Prize winners....\n",
      " -> Added: Inspiring individuals...\n",
      " -> Added: Rock and Roll Hall of Fame fif...\n",
      " -> Added: Open space: some ideas for its...\n",
      "--- Processing Page 197 | Collected so far: 477/500 ---\n",
      " -> Added: Agriculture Canada recipients ...\n",
      " -> Added: Rock & Roll Hall of Fame induc...\n",
      " -> Added: Rock & Roll Hall of Fame induc...\n",
      " -> Added: Rock & Roll Hall of Fame induc...\n",
      " -> Added: The fourth annual induction di...\n",
      " -> Added: The second annual Rock and Rol...\n",
      " -> Added: Rock and Roll Hall of Fame...\n",
      " -> Added: Viaje al cine espa√±ol...\n",
      " -> Added: Material process...\n",
      " -> Added: AR100 & CSR...\n",
      " -> Added: Peterson's scholarships, grant...\n",
      "--- Processing Page 198 | Collected so far: 488/500 ---\n",
      " -> Added: [Gold medal awarded our dahlia...\n",
      " -> Added: Golden Jubilee of E. Gurney Hi...\n",
      " -> Added: Bericht der Beurtheilungs-Comm...\n",
      " -> Added: Masters of the Crafts...\n",
      " -> Added: Scale...\n",
      " -> Added: I pregj delle belle arti...\n",
      " -> Added: History of the Loring Prize pl...\n",
      " -> Added: Prize peonies...\n",
      " -> Added: Second nature...\n",
      "--- Processing Page 199 | Collected so far: 497/500 ---\n",
      " -> Added: √ñzlem G√ºnyol & Mustafa Kunt, S...\n",
      " -> Added: Rock & Roll Hall of Fame 24th ...\n",
      " -> Added: Center of the universe...\n",
      "\n",
      "DataFrame Created Successfully:\n",
      "                                               title  \\\n",
      "0        Les Prix de Vertu, fond√©s par M. de Montyon   \n",
      "1  Teachers With Class... True Stories Of Great T...   \n",
      "2                    Rock and Roll Hall of Fame 1994   \n",
      "3                                 Stories of heroism   \n",
      "4                                    La colina vac√≠a   \n",
      "\n",
      "                                   author published_year  \\\n",
      "0                           Fr√©d√©ric Lock           1876   \n",
      "1  Marsha Serling Goldberg, Sonia Feldman     March 2003   \n",
      "2   Rock and Roll Hall of Fame Foundation           1994   \n",
      "3                          B. Chakravorty           None   \n",
      "4                              Ana Arn√°iz           None   \n",
      "\n",
      "                                             subject language  \\\n",
      "0  Montyon, Antoine-Jean-Baptiste-Robert Auget, b...      fre   \n",
      "1  Teaching, Teacher-student relationships, Educa...      eng   \n",
      "2  Rock and Roll Hall of Fame Foundation, History...      eng   \n",
      "3  Biography, Military decorations, Armed Forces,...     None   \n",
      "4  Awards, Architecture, History, Sculptors, Arch...     None   \n",
      "\n",
      "                                               cover  \n",
      "0  https://covers.openlibrary.org/b/id/6324499-L.jpg  \n",
      "1   https://covers.openlibrary.org/b/id/469736-L.jpg  \n",
      "2  https://covers.openlibrary.org/b/id/9964834-L.jpg  \n",
      "3                                               None  \n",
      "4                                               None  \n",
      "Total rows: 520\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "# 1. Initialize empty lists for the columns\n",
    "titles = []\n",
    "authors = []\n",
    "published_years = []\n",
    "subjects_list = []\n",
    "languages = []\n",
    "covers = []\n",
    "\n",
    "# Headers to act like a real browser\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "\n",
    "# 2. START FROM PAGE 26, LOOP UNTIL WE HAVE 500 COMPLETE BOOKS\n",
    "page = 26\n",
    "while len(titles) < 500:\n",
    "    \n",
    "    link_main = f\"https://openlibrary.org/search.json?q=subject_key%3A%22awards%22&page={page}&limit=20\"\n",
    "    print(f\"--- Processing Page {page} | Collected so far: {len(titles)}/500 ---\")\n",
    "    \n",
    "    try:\n",
    "        # Get the Search API JSON\n",
    "        response = requests.get(link_main, headers=headers)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Skipping page {page} due to error.\")\n",
    "            page += 1\n",
    "            continue\n",
    "            \n",
    "        data = response.json()\n",
    "        docs = data.get('docs', [])\n",
    "        \n",
    "        # If no docs returned, we might have reached the end of results\n",
    "        if not docs:\n",
    "            print(\"No more results found.\")\n",
    "            break\n",
    "        \n",
    "        # 3. Iterate through the keys in the search results\n",
    "        for doc in docs:\n",
    "            \n",
    "            # Stop immediately if we reached 500 inside the page loop\n",
    "            if len(titles) >= 500:\n",
    "                break\n",
    "\n",
    "            # Initialize temporary variables for this specific book\n",
    "            # We will only append these to the main lists if ALL are found\n",
    "            current_title = None\n",
    "            current_author = None\n",
    "            current_year = None\n",
    "            current_subject = None\n",
    "            current_lang = None\n",
    "            current_cover = None\n",
    "\n",
    "            # Prefer the 'cover_edition_key' (Book) if available, otherwise 'key' (Work)\n",
    "            key_id = doc.get('cover_edition_key')\n",
    "            if key_id:\n",
    "                key = f\"/books/{key_id}\"\n",
    "            else:\n",
    "                key = doc.get('key')\n",
    "\n",
    "            if not key:\n",
    "                continue\n",
    "\n",
    "            # Construct URLs\n",
    "            link_book_json = f\"https://openlibrary.org{key}.json\"\n",
    "            link_book_html = f\"https://openlibrary.org{key}\"\n",
    "            \n",
    "            # --- PART A: GET DATA FROM BOOK JSON ---\n",
    "            try:\n",
    "                # Request the specific book JSON\n",
    "                book_resp = requests.get(link_book_json, headers=headers)\n",
    "                book_json = book_resp.json() if book_resp.status_code == 200 else {}\n",
    "                \n",
    "                # Title\n",
    "                current_title = book_json.get('title')\n",
    "                \n",
    "                # Author (from search doc to ensure we get a name, not just an ID)\n",
    "                a_val = doc.get('author_name') \n",
    "                if a_val:\n",
    "                    current_author = \", \".join(a_val)\n",
    "\n",
    "                # Published Year / Date\n",
    "                current_year = book_json.get('publish_date')\n",
    "\n",
    "                # Subjects\n",
    "                s_val = book_json.get('subjects')\n",
    "                if s_val and isinstance(s_val, list):\n",
    "                    current_subject = \", \".join(s_val)\n",
    "\n",
    "                # Language\n",
    "                l_val = book_json.get('languages')\n",
    "                if l_val and isinstance(l_val, list):\n",
    "                    langs = [item.get('key', '').split('/')[-1] for item in l_val if 'key' in item]\n",
    "                    if langs:\n",
    "                        current_lang = \", \".join(langs)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error parsing JSON for {key}: {e}\")\n",
    "                # If JSON fails, the variables remain None\n",
    "\n",
    "            # --- PART B: GET COVER FROM HTML SCRAPING ---\n",
    "            # Only bother scraping if we have the previous data (Optimization)\n",
    "            if current_title and current_author and current_year and current_subject and current_lang:\n",
    "                try:\n",
    "                    html_resp = requests.get(link_book_html, headers=headers)\n",
    "                    \n",
    "                    if html_resp.status_code == 200:\n",
    "                        soup = BeautifulSoup(html_resp.content, 'html.parser')\n",
    "                        \n",
    "                        cover_tag = soup.find(\"a\", class_=\"coverLook\")\n",
    "                        if cover_tag and cover_tag.get('href'):\n",
    "                            current_cover = \"https:\" + cover_tag.get('href')\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error scraping HTML for {key}: {e}\")\n",
    "\n",
    "            # --- FINAL VALIDATION ---\n",
    "            # Only add to dataset if ALL fields are present (not None)\n",
    "            if (current_title and current_author and current_year and \n",
    "                current_subject and current_lang and current_cover):\n",
    "                \n",
    "                titles.append(current_title)\n",
    "                authors.append(current_author)\n",
    "                published_years.append(current_year)\n",
    "                subjects_list.append(current_subject)\n",
    "                languages.append(current_lang)\n",
    "                covers.append(current_cover)\n",
    "                print(f\" -> Added: {current_title[:30]}...\")\n",
    "            else:\n",
    "                # print(f\" -> Skipped (Incomplete Data): {key}\")\n",
    "                pass\n",
    "\n",
    "            # Sleep to prevent IP ban\n",
    "            time.sleep(0.5)\n",
    "\n",
    "        # Increment page number for the while loop\n",
    "        page += 1\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Critical Error on Page {page}: {e}\")\n",
    "        page += 1\n",
    "\n",
    "# 4. Create the Pandas DataFrame\n",
    "df_api_fullrows = pd.DataFrame({\n",
    "    'title': titles,\n",
    "    'author': authors,\n",
    "    'published_year': published_years,\n",
    "    'subject': subjects_list,\n",
    "    'language': languages,\n",
    "    'cover': covers\n",
    "})\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\nDataFrame Created Successfully:\")\n",
    "print(df.head())\n",
    "print(f\"Total rows: {len(df)}\")\n",
    "\n",
    "# Save to CSV (Optional)\n",
    "# df.to_csv(\"books_scraped_full_500.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd4a9738-e60f-475b-a35c-b44e8a2b4167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>published_year</th>\n",
       "      <th>subject</th>\n",
       "      <th>language</th>\n",
       "      <th>cover</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Les Prix de Vertu, fond√©s par M. de Montyon</td>\n",
       "      <td>Fr√©d√©ric Lock</td>\n",
       "      <td>1876</td>\n",
       "      <td>Montyon, Antoine-Jean-Baptiste-Robert Auget, b...</td>\n",
       "      <td>fre</td>\n",
       "      <td>https://covers.openlibrary.org/b/id/6324499-L.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Teachers With Class... True Stories Of Great T...</td>\n",
       "      <td>Marsha Serling Goldberg, Sonia Feldman</td>\n",
       "      <td>March 2003</td>\n",
       "      <td>Teaching, Teacher-student relationships, Educa...</td>\n",
       "      <td>eng</td>\n",
       "      <td>https://covers.openlibrary.org/b/id/469736-L.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rock and Roll Hall of Fame 1994</td>\n",
       "      <td>Rock and Roll Hall of Fame Foundation</td>\n",
       "      <td>1994</td>\n",
       "      <td>Rock and Roll Hall of Fame Foundation, History...</td>\n",
       "      <td>eng</td>\n",
       "      <td>https://covers.openlibrary.org/b/id/9964834-L.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The third annual Rock &amp; Roll Hall of Fame indu...</td>\n",
       "      <td>Rock and Roll Hall of Fame Foundation</td>\n",
       "      <td>1988</td>\n",
       "      <td>Supremes (Musical group), Beatles, Rock and Ro...</td>\n",
       "      <td>eng</td>\n",
       "      <td>https://covers.openlibrary.org/b/id/10018469-L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rock and Roll Hall of Fame 1990</td>\n",
       "      <td>Rock and Roll Hall of Fame Foundation</td>\n",
       "      <td>1990</td>\n",
       "      <td>Kinks (Musical group), Platters (Musical group...</td>\n",
       "      <td>eng</td>\n",
       "      <td>https://covers.openlibrary.org/b/id/9531446-L.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>Prize peonies</td>\n",
       "      <td>Edward P. Schwartz Peony Gardens</td>\n",
       "      <td>1929</td>\n",
       "      <td>Peonies, Nursery stock, Catalogs, Varieties, A...</td>\n",
       "      <td>eng</td>\n",
       "      <td>https://covers.openlibrary.org/b/id/8136937-L.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>Second nature</td>\n",
       "      <td>Architectural League of New York</td>\n",
       "      <td>2001</td>\n",
       "      <td>Young Architects Forum, Architecture -- Awards...</td>\n",
       "      <td>eng</td>\n",
       "      <td>https://covers.openlibrary.org/b/id/812663-L.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>√ñzlem G√ºnyol &amp; Mustafa Kunt, Sandra Kuhne, Reg...</td>\n",
       "      <td>Ulrike Lorenz</td>\n",
       "      <td>2009</td>\n",
       "      <td>Modern Art, Art, Exhibitions, Awards</td>\n",
       "      <td>ger</td>\n",
       "      <td>https://covers.openlibrary.org/b/id/9882610-L.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>Rock &amp; Roll Hall of Fame 24th annual induction...</td>\n",
       "      <td>Rock and Roll Hall of Fame Foundation</td>\n",
       "      <td>2009</td>\n",
       "      <td>Run-D.M.C. (Musical group), Rock and Roll Hall...</td>\n",
       "      <td>eng</td>\n",
       "      <td>https://covers.openlibrary.org/b/id/8339125-L.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>Center of the universe</td>\n",
       "      <td>Fred Chappell</td>\n",
       "      <td>2007</td>\n",
       "      <td>Awards</td>\n",
       "      <td>eng</td>\n",
       "      <td>https://covers.openlibrary.org/b/id/7234661-L.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>492 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0          Les Prix de Vertu, fond√©s par M. de Montyon   \n",
       "1    Teachers With Class... True Stories Of Great T...   \n",
       "2                      Rock and Roll Hall of Fame 1994   \n",
       "3    The third annual Rock & Roll Hall of Fame indu...   \n",
       "4                      Rock and Roll Hall of Fame 1990   \n",
       "..                                                 ...   \n",
       "495                                      Prize peonies   \n",
       "496                                      Second nature   \n",
       "497  √ñzlem G√ºnyol & Mustafa Kunt, Sandra Kuhne, Reg...   \n",
       "498  Rock & Roll Hall of Fame 24th annual induction...   \n",
       "499                             Center of the universe   \n",
       "\n",
       "                                     author published_year  \\\n",
       "0                             Fr√©d√©ric Lock           1876   \n",
       "1    Marsha Serling Goldberg, Sonia Feldman     March 2003   \n",
       "2     Rock and Roll Hall of Fame Foundation           1994   \n",
       "3     Rock and Roll Hall of Fame Foundation           1988   \n",
       "4     Rock and Roll Hall of Fame Foundation           1990   \n",
       "..                                      ...            ...   \n",
       "495        Edward P. Schwartz Peony Gardens           1929   \n",
       "496        Architectural League of New York           2001   \n",
       "497                           Ulrike Lorenz           2009   \n",
       "498   Rock and Roll Hall of Fame Foundation           2009   \n",
       "499                           Fred Chappell           2007   \n",
       "\n",
       "                                               subject language  \\\n",
       "0    Montyon, Antoine-Jean-Baptiste-Robert Auget, b...      fre   \n",
       "1    Teaching, Teacher-student relationships, Educa...      eng   \n",
       "2    Rock and Roll Hall of Fame Foundation, History...      eng   \n",
       "3    Supremes (Musical group), Beatles, Rock and Ro...      eng   \n",
       "4    Kinks (Musical group), Platters (Musical group...      eng   \n",
       "..                                                 ...      ...   \n",
       "495  Peonies, Nursery stock, Catalogs, Varieties, A...      eng   \n",
       "496  Young Architects Forum, Architecture -- Awards...      eng   \n",
       "497               Modern Art, Art, Exhibitions, Awards      ger   \n",
       "498  Run-D.M.C. (Musical group), Rock and Roll Hall...      eng   \n",
       "499                                             Awards      eng   \n",
       "\n",
       "                                                 cover  \n",
       "0    https://covers.openlibrary.org/b/id/6324499-L.jpg  \n",
       "1     https://covers.openlibrary.org/b/id/469736-L.jpg  \n",
       "2    https://covers.openlibrary.org/b/id/9964834-L.jpg  \n",
       "3    https://covers.openlibrary.org/b/id/10018469-L...  \n",
       "4    https://covers.openlibrary.org/b/id/9531446-L.jpg  \n",
       "..                                                 ...  \n",
       "495  https://covers.openlibrary.org/b/id/8136937-L.jpg  \n",
       "496   https://covers.openlibrary.org/b/id/812663-L.jpg  \n",
       "497  https://covers.openlibrary.org/b/id/9882610-L.jpg  \n",
       "498  https://covers.openlibrary.org/b/id/8339125-L.jpg  \n",
       "499  https://covers.openlibrary.org/b/id/7234661-L.jpg  \n",
       "\n",
       "[492 rows x 6 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_api_fullrows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9278943-6f8b-4b29-a0d1-7be8577f73da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_api_fullrows.drop_duplicates(subset=['title'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c863437-48d1-4871-bd0c-dc5cd71a6d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate titles: 0\n",
      "\n",
      "No duplicate titles found.\n"
     ]
    }
   ],
   "source": [
    "duplicate_count = df_api_fullrows.duplicated(subset=['title']).sum()\n",
    "print(f\"Number of duplicate titles: {duplicate_count}\")\n",
    "\n",
    "# Show the actual rows that are duplicates\n",
    "# keep=False shows ALL instances of the duplicates (the original and the repeats)\n",
    "duplicates = df_api_fullrows[df_api_fullrows.duplicated(subset=['title'], keep=False)]\n",
    "\n",
    "if not duplicates.empty:\n",
    "    print(\"\\nDuplicate entries found:\")\n",
    "    print(duplicates[['title', 'author']].sort_values(by='title').head(10)) # Show first 10\n",
    "else:\n",
    "    print(\"\\nNo duplicate titles found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b04b9b43-84cf-4d87-b269-5e5a84cc6037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Processing Page 200 ---\n",
      "--- Processing Page 201 ---\n",
      "--- Processing Page 202 ---\n",
      "--- Processing Page 203 ---\n",
      "--- Processing Page 204 ---\n",
      "--- Processing Page 205 ---\n",
      "--- Processing Page 206 ---\n",
      "--- Processing Page 207 ---\n",
      "--- Processing Page 208 ---\n",
      "--- Processing Page 209 ---\n",
      "--- Processing Page 210 ---\n",
      "--- Processing Page 211 ---\n",
      "--- Processing Page 212 ---\n",
      "--- Processing Page 213 ---\n",
      "--- Processing Page 214 ---\n",
      "--- Processing Page 215 ---\n",
      "--- Processing Page 216 ---\n",
      "--- Processing Page 217 ---\n",
      "--- Processing Page 218 ---\n",
      "--- Processing Page 219 ---\n",
      "--- Processing Page 220 ---\n",
      "--- Processing Page 221 ---\n",
      "--- Processing Page 222 ---\n",
      "--- Processing Page 223 ---\n",
      "--- Processing Page 224 ---\n",
      "--- Processing Page 225 ---\n",
      "--- Processing Page 226 ---\n",
      "--- Processing Page 227 ---\n",
      "--- Processing Page 228 ---\n",
      "--- Processing Page 229 ---\n",
      "--- Processing Page 230 ---\n",
      "--- Processing Page 231 ---\n",
      "--- Processing Page 232 ---\n",
      "--- Processing Page 233 ---\n",
      "--- Processing Page 234 ---\n",
      "--- Processing Page 235 ---\n",
      "--- Processing Page 236 ---\n",
      "--- Processing Page 237 ---\n",
      "--- Processing Page 238 ---\n",
      "--- Processing Page 239 ---\n",
      "--- Processing Page 240 ---\n",
      "\n",
      "Collected 53 extra rows (before deduplication).\n",
      "Rows in df_extras after dropping duplicates: 53\n",
      "\n",
      "Merged successfully.\n",
      "Total rows in df_api_fullrows: 545\n",
      "                                                 title  \\\n",
      "540                25 Jahre deutscher Architekturpreis   \n",
      "541     Premio Nacional de Ciencias y Artes, 1945-1990   \n",
      "542                                    Turner Prize 10   \n",
      "543   The third Prince of Wales Prize in Urban Design.   \n",
      "544  The ESPN Baseball Encyclopedia, Fifth Edition ...   \n",
      "\n",
      "                                      author     published_year  \\\n",
      "540                          J√ºrgen Joedicke               1997   \n",
      "541                    V√≠ctor D√≠az Arciniega               1991   \n",
      "542                             Helen Little               2010   \n",
      "543  Eduard F. Sekler, Alexander Von Hoffman               1993   \n",
      "544             Gary Gillette, Peter Gammons  February 25, 2008   \n",
      "\n",
      "                                               subject language  \\\n",
      "540  Architecture -- Competitions -- Germany, Archi...      ger   \n",
      "541  Biography -- 20th century -- Dictionaries., Aw...      spa   \n",
      "542  Turner Prize, History, British Art, Awards, Ar...      eng   \n",
      "543  Maki, Fumihiko, 1928-  -- Awards., Snozzi, Lui...      eng   \n",
      "544  Baseball, Sports & Recreation, Sports, Basebal...      eng   \n",
      "\n",
      "                                                 cover  \n",
      "540  https://covers.openlibrary.org/b/id/2238953-L.jpg  \n",
      "541  https://covers.openlibrary.org/b/id/3921431-L.jpg  \n",
      "542  https://covers.openlibrary.org/b/id/12151232-L...  \n",
      "543  https://covers.openlibrary.org/b/id/1677743-L.jpg  \n",
      "544  https://covers.openlibrary.org/b/id/2741331-L.jpg  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "# 1. Initialize empty lists for the new batch\n",
    "titles = []\n",
    "authors = []\n",
    "published_years = []\n",
    "subjects_list = []\n",
    "languages = []\n",
    "covers = []\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "\n",
    "# 2. Loop specifically from page 200 to 240\n",
    "# range(200, 241) includes 200 and ends at 240\n",
    "for page in range(200, 241):\n",
    "    \n",
    "    link_main = f\"https://openlibrary.org/search.json?q=subject_key%3A%22awards%22&page={page}&limit=20\"\n",
    "    print(f\"--- Processing Page {page} ---\")\n",
    "    \n",
    "    try:\n",
    "        # Get Search API\n",
    "        response = requests.get(link_main, headers=headers)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Skipping page {page} (Status {response.status_code})\")\n",
    "            continue\n",
    "            \n",
    "        data = response.json()\n",
    "        docs = data.get('docs', [])\n",
    "        \n",
    "        if not docs:\n",
    "            print(f\"No results on page {page}.\")\n",
    "            continue\n",
    "        \n",
    "        # 3. Iterate books\n",
    "        for doc in docs:\n",
    "            \n",
    "            # Temp variables\n",
    "            current_title = None\n",
    "            current_author = None\n",
    "            current_year = None\n",
    "            current_subject = None\n",
    "            current_lang = None\n",
    "            current_cover = None\n",
    "\n",
    "            # Get Key (Book > Work)\n",
    "            key_id = doc.get('cover_edition_key')\n",
    "            if key_id:\n",
    "                key = f\"/books/{key_id}\"\n",
    "            else:\n",
    "                key = doc.get('key') # Fallback\n",
    "\n",
    "            if not key:\n",
    "                continue\n",
    "\n",
    "            link_book_json = f\"https://openlibrary.org{key}.json\"\n",
    "            link_book_html = f\"https://openlibrary.org{key}\"\n",
    "            \n",
    "            # --- PART A: JSON Metadata ---\n",
    "            try:\n",
    "                book_resp = requests.get(link_book_json, headers=headers)\n",
    "                book_json = book_resp.json() if book_resp.status_code == 200 else {}\n",
    "                \n",
    "                # Title\n",
    "                current_title = book_json.get('title')\n",
    "                \n",
    "                # Author (From search doc for safety)\n",
    "                a_val = doc.get('author_name') \n",
    "                if a_val:\n",
    "                    current_author = \", \".join(a_val)\n",
    "\n",
    "                # Published Year\n",
    "                current_year = book_json.get('publish_date')\n",
    "\n",
    "                # Subjects\n",
    "                s_val = book_json.get('subjects')\n",
    "                if s_val and isinstance(s_val, list):\n",
    "                    current_subject = \", \".join(s_val)\n",
    "\n",
    "                # Language\n",
    "                l_val = book_json.get('languages')\n",
    "                if l_val and isinstance(l_val, list):\n",
    "                    langs = [item.get('key', '').split('/')[-1] for item in l_val if 'key' in item]\n",
    "                    if langs:\n",
    "                        current_lang = \", \".join(langs)\n",
    "\n",
    "            except:\n",
    "                pass # Fail silently, validation will catch it later\n",
    "\n",
    "            # --- PART B: HTML Cover ---\n",
    "            # Optimization: Only scrape if other data exists\n",
    "            if current_title and current_author and current_year and current_subject and current_lang:\n",
    "                try:\n",
    "                    html_resp = requests.get(link_book_html, headers=headers)\n",
    "                    if html_resp.status_code == 200:\n",
    "                        soup = BeautifulSoup(html_resp.content, 'html.parser')\n",
    "                        cover_tag = soup.find(\"a\", class_=\"coverLook\")\n",
    "                        if cover_tag and cover_tag.get('href'):\n",
    "                            current_cover = \"https:\" + cover_tag.get('href')\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "            # --- VALIDATION: Ensure NO null values ---\n",
    "            if (current_title and current_author and current_year and \n",
    "                current_subject and current_lang and current_cover):\n",
    "                \n",
    "                titles.append(current_title)\n",
    "                authors.append(current_author)\n",
    "                published_years.append(current_year)\n",
    "                subjects_list.append(current_subject)\n",
    "                languages.append(current_lang)\n",
    "                covers.append(current_cover)\n",
    "            \n",
    "            # Sleep to prevent bans\n",
    "            time.sleep(0.5)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error on page {page}: {e}\")\n",
    "\n",
    "# 4. Create df_extras\n",
    "df_extras = pd.DataFrame({\n",
    "    'title': titles,\n",
    "    'author': authors,\n",
    "    'published_year': published_years,\n",
    "    'subject': subjects_list,\n",
    "    'language': languages,\n",
    "    'cover': covers\n",
    "})\n",
    "\n",
    "print(f\"\\nCollected {len(df_extras)} extra rows (before deduplication).\")\n",
    "\n",
    "# 5. Drop duplicates in df_extras\n",
    "df_extras.drop_duplicates(subset=['title'], inplace=True)\n",
    "print(f\"Rows in df_extras after dropping duplicates: {len(df_extras)}\")\n",
    "\n",
    "# 6. Join to df_api_fullrows\n",
    "# Note: Assuming df_api_fullrows exists from your previous code\n",
    "if 'df_api_fullrows' in locals() or 'df_api_fullrows' in globals():\n",
    "    df_api_fullrows = pd.concat([df_api_fullrows, df_extras], ignore_index=True)\n",
    "    \n",
    "    # Optional: You might want to drop duplicates again after the merge\n",
    "    # in case the new books overlap with the old books\n",
    "    df_api_fullrows.drop_duplicates(subset=['title'], inplace=True)\n",
    "    \n",
    "    print(\"\\nMerged successfully.\")\n",
    "    print(f\"Total rows in df_api_fullrows: {len(df_api_fullrows)}\")\n",
    "    print(df_api_fullrows.tail())\n",
    "else:\n",
    "    print(\"\\nWARNING: df_api_fullrows not found. created df_extras only.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9365d9ca-8aec-4080-a182-0968345a4ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_api_fullrows.to_csv(\"books_api_scraped_no_null.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520a5c32-c531-4da9-823e-12bb3abf8560",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
